# Задание 1:
```bash
Представьте, что у вас есть микро-сервисное приложение, развернутое в Kubernetes
кластере, которое состоит из нескольких сервисов. Один из сервисов начинает работать
медленно и задерживать обработку запросов. Как вы будете диагностировать и устранять
проблему?
```

1) Необходимо убедится какой сервисов медленно работает .
Расследование:
* Анализ метрик prometheus (для удобства лучше Grafana), посмотреть на каких узлах кластера изменились показатели (время ответа, нагрузка на сервис, задержки в базе данных и др.)
* Анализ логов используя ELK Stack (Elasticsearch, Logstash, Kibana), посмореть ошибки от каких сервисов поступают.
* Aнализ логов и состояния подов:
```bash
kubectl logs <pod-name> -n <namespace>
kubectl get pods -n 
# подробная информация о подах 
kubectl describe pod <pod-name> -n <namespace>
# проверка использования ресурсов подов
kubectl top pod <pod-name> -n <namespace>
```
* Проверьте, не находятся ли поды в состоянии CrashLoopBackOff или Pending, что может указывать на проблемы с развертыванием или зависания контейнеров.

Устранение проблемы:
* В случае если наш микросервис зависит от стороннего сервиса , который сейчас работает не корректно, необходимо обратиться в поддержку стороннего сервиса.
* В случае если сервис стал работать медленно из-за какого-либо сбоя, можно попытаться перезапустить поды, чтобы устранить временную проблему.
```bash
kubectl rollout restart deployment <deployment-name> -n <namespace>
```
* В случае нехватки ресурсов на подах , отредактировать настроечный файл(секцию resources):
```bash 
# открыть на редактирование
kubectl edit pod <pod-name> -n <namespace>
# применить изменения 
kubectl apply -f <file.yaml>
# для проверки ресурсов после добавления 
kubectl describe pod <pod-name> -n <namespace>
```
* Если нагрузка на под велика и он не может справиться, можно масштабировать количество реплик:
```bash
kubectl scale deployment <deployment-name> --replicas=<desired-number> -n <namespace>
```
Это увеличит количество подов в деплойменте и поможет распределить нагрузку.

# Задание 2:
```bash
На общем информационном дашборде в Grafana данные по одному из кластеров не
отображаются, почему такое может произойти и как это можно исправить?
```
Как правило метрики кластера собирают через prometheus, добавляя его в grafana как source
* проверяем доступность кластера и состояние узлов :
```bash 
kubectl cluster-info
kubectl get nodes
kubectl get pods --all-namespaces
```
* Команда kubectl get componentstatuses покажет статус ключевых компонентов кластера, таких как scheduler, controller-manager и etcd:
```bash 
kubectl get componentstatuses
```
* Убедимся, что pod с node-exporter запущен: 
```bash
kubectl get pods -n <namespace> -l app=node-exporter
# Если node-exporter развернут как DaemonSet
kubectl get daemonset node-exporter -n <namespace>
# Проверка логов пода node-exporter
kubectl logs <pod-name> -n <namespace>
```
* проверить доступность экспортера :
```bash
nc -zv <node-ip> 9100
```
Решение :
* Перезапуск пода в случае зависания:
```bash
kubectl delete pod <pod-name> -n <namespace>
```
* в случае нехватки ресурса на поде в node-exporter , добавить ресурсов (см. п.1)
* в случае сетевых проблем , настроить доступность портов (Network Policies , iptables и другие)
* проверить корректность настройки dashboard в grafana.


# Задание 3:
```bash
Вам нужно настроить систему мониторинга за важными частями инфраструктуры, с чего
вы бы начали и за какими важными метриками наблюдали? Какие инструменты
использовали бы и почему?
```
Важные части инфраструктуры k8s, за которыми необходимо наблюдать:
Узлы (Nodes):
* CPU Usage: Загрузка CPU на узлах, например, через node_cpu_seconds_total.
* Memory Usage: Использование памяти на узлах, через метрики типа 
* node_memory_MemAvailable_bytes и node_memory_MemTotal_bytes.
* Disk Usage: Использование дискового пространства, например, node_filesystem_avail и node_filesystem_size.
* Node Status: Состояние узлов — Ready, NotReady, ошибок в компонентах узла, через kubectl get nodes.

Поды (Pods):
* Pod Health: Статус подов (работает ли под, есть ли ошибки или перезапуски).
* Pod Resource Usage: Использование ресурсов — CPU, память на уровне подов (container_cpu_usage_seconds_total, container_memory_usage_bytes).
* Pod Restarts: Количество перезапусков подов, которые могут свидетельствовать о нестабильности, через kube_pod_container_status_restarts_total.

Сервисы и деплойменты:
* Request Latency: Задержка запросов к сервисам.
* Request Rate: Частота запросов к сервисам.
* Error Rate: Ошибки при обработке запросов (например, HTTP 4xx/5xx ошибки).

Для сбора и визуализации метрик использовал бы стек: Prometheus+Grafana
Prometheus — это ведущий инструмент для мониторинга и сбора метрик в Kubernetes. Он поддерживает динамическое скалирование, автоматическое обнаружение сервисов и подов, а также мощный язык запросов (PromQL), который позволяет гибко анализировать метрики.
Grafana - хорошо работает с prometheus, имеет гибкую систему настроек дашбордов и алертов, а также интеграция с каналами оповещений (slack, telegramm и др.)

# Задание 4:
```bash
После добавления новых нод в кластер, некоторые поды продолжают запускаться только
на старых нодах. Какие могут быть причины и как это можно исправить?
```

* Проблемы с размещением подов из-за ограничений ресурсов
Ресурсные ограничения (CPU, память) на новых узлах могут быть недостаточными для запуска подов. Kubernetes может не размещать поды на новых узлах, если они не могут удовлетворить требования по ресурсам, указанным в спецификации пода.
Проверим, достаточно ли ресурсов (CPU, память) на новых узлах, чтобы разместить поды:
```bash
kubectl describe nodes <new-node-name>
```
в случае нехватки ресурса на поде , добавим ресурсов (см. п.1)

* Неправильно настроенные taints или tolerations
Проверим наличие taints на новых узлах с помощью команды:
```bash
kubectl describe node <new-node-name> | grep Taints
```
Если taints на новых узлах не нужны, их можно удалить с помощью:
```bash
kubectl taint nodes <new-node-name> key=value:NoSchedule-
```
Или добавить toleration в манифест пода.

* убедимся, что в манифестах подов не используются строгие nodeSelector, которые ограничивают запуск подов , только на узлах с определенными метками.
При необходимости добавим метки:
```bash
# проверить метки
kubectl get nodes --show-labels
# добавить метки
kubectl label nodes <new-node-name> <key>=<value>
```

* Проверим логи kube-scheduler для поиска возможных ошибок, которые могут мешать размещению подов на новых узлах
```bash
kubectl logs -n kube-system kube-scheduler-<your-node-name>
```

# Задание 5:
```bash
Во время вашей смены в одной из систем мониторинга вы обнаружили критический алерт,
который сигнализирует о поломке важного микро-сервиса в k8s кластере. Опишите процесс
решения инцидента.
```
Выделю несколько последовательных этапов реагирования:
1. Проверка метрик и логов (алерта)
Используя Prometheus/Grafana смотрим что именно происходит с сервисом (например, повышение использования CPU или памяти, частые перезапуски контейнеров).
Проверьте логи сервисов через ELK, чтобы понять, были ли исключения, ошибки или сбои на уровне приложения.
2. Проверка состояния кластера и подов
Необходимо разобраться, что происходит в самом кластере, а также проанализировать состояние подов и узлов.
```bash
# состояние подов, относящихся к сервису
kubectl get pods -n <namespace> --selector=<label-selector>
# подробная информация
kubectl describe pod <pod-name> -n <namespace>
```

2.2. Проверка логов подов
Для подов, находящихся в состоянии ошибки или перезапуска, следует посмотреть логи, чтобы получить больше информации о причине сбоя.
```bash
--previous позволяет увидеть логи предыдущего контейнера в случае перезапуска.
kubectl logs <pod-name> -n <namespace> --previous
```

2.3. Проверка состояния узлов
Проверяем что узлы работают нормально, что на них достаточно ресурсов (CPU, память), и нет taints или других ограничений.
Если поды не могут быть размещены на новых узлах, выполните команду:
```bash
kubectl describe node <node-name>
```

3. Диагностика проблем с зависимыми сервисами
Иногда сервис может зависать или работать с ошибками из-за проблем с зависимыми компонентами. Можем по другим алертам понять что сторонний сервис по времени раньше начал отдавать ошибки. Вероятней дело будет в стороннем сервисе.

Если сервис зависит от базы данных (например, PostgreSQL, MySQL) или кэша (например, Redis), проверьте их состояние через kubectl или системные логи.
```bash
kubectl get pods -n <namespace> -l app=<db-app-name>
```

Решение проблемы

4. Рестарт подов
Если сервис временно стал нестабильным, можно попробовать перезапустить поды.
```bash
# Kubernetes автоматически развернет новый под, если у вас настроен реплика-сет или деплоймент.
kubectl delete pod <pod-name> -n <namespace>
```

5. Решение проблем с ресурсами
Если причиной является недостаток ресурсов (например, CPU или память), возможно, нужно увеличить ресурсы для подов, масштабировать их количество или обновить узлы кластера.

Пример для увеличения ресурсов в манифесте пода:
```bash
resources:
  requests:
    memory: "512Mi"
    cpu: "500m"
  limits:
    memory: "1Gi"
    cpu: "1"
```

# Задание 6:
```bash
В чем проблема такого докерфайла и как его можно улучшить?
FROM golang:1.18
WORKDIR /app
COPY go.mod go.sum ./
RUN go mod download
COPY *.go ./
RUN go build -o /docker-go-image
EXPOSE 8080
CMD ["/docker-go-image"]
```

Улучшение:
* Лучше применить многоступенчатую сборку для уменьшения размера итогового образа. В данном случае, можно использовать два этапа: один для сборки приложения, другой — для запуска. 
* Команда ```COPY *.go ./``` - что копирует все Go-файлы в рабочую директорию  . Разделим копирование зависимостей и исходников, чтобы использовать кэширование Docker и не пересобирать все при изменении одного файла.
Сначала копируются только go.mod и go.sum для того, чтобы загрузить зависимости. Это позволяет Docker использовать кэш для загрузки зависимостей, если они не менялись, и не пересобирать весь проект при каждом изменении исходного кода.
```bash
# Этап сборки
FROM golang:1.18 AS builder
WORKDIR /app
# Копируем только go.mod и go.sum и загружаем зависимости
COPY go.mod go.sum ./
RUN go mod download
# Копируем остальные исходники
COPY . ./
# Собираем бинарный файл
RUN go build -o /docker-go-image
# Этап финального образа
FROM alpine:latest
# Устанавливаем необходимые зависимости для работы с Go (например, для работы с libc)
RUN apk --no-cache add ca-certificates
# Копируем бинарник из предыдущего этапа
COPY --from=builder /docker-go-image /docker-go-image
EXPOSE 8080
# Запускаем приложение
CMD ["/docker-go-image"]
```
